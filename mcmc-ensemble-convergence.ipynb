{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC ensemble convergence test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import arviz\n",
    "import emcee\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an ensemble\n",
    "\n",
    "Lets take the tutorial example of running [emcee](https://emcee.readthedocs.io/en/stable/tutorials/quickstart/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain shape: (10000, 32, 5)\n"
     ]
    }
   ],
   "source": [
    "def log_prob(x, ivar):\n",
    "    return -0.5 * np.sum(ivar * x ** 2)\n",
    "\n",
    "ndim, nwalkers = 5, 32\n",
    "ivar = 1. / np.random.rand(ndim)\n",
    "p0 = np.random.randn(nwalkers, ndim)\n",
    "\n",
    "nsteps = 10000\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[ivar])\n",
    "sampler.run_mcmc(p0, nsteps)\n",
    "\n",
    "print(\"Chain shape:\", sampler.get_chain().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two things we need to improve here:\n",
    "\n",
    "1) we want to remove some warm-up points from the beginning of each chain. Lets take away the first quarter of the chain.\n",
    "\n",
    "2) To reliably test the stationarity of a chain, we need *several* independent chains that should appear indistinguishable. Because the ensemble proposals entangles the walkers among each other, one ensemble is not enough. We need a few independently run ensembles. Four is usually enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ensemble 1: warm-up ...\n",
      "ensemble 1: sampling ...\n",
      "ensemble 2: warm-up ...\n",
      "ensemble 2: sampling ...\n",
      "ensemble 3: warm-up ...\n",
      "ensemble 3: sampling ...\n",
      "ensemble 4: warm-up ...\n",
      "ensemble 4: sampling ...\n"
     ]
    }
   ],
   "source": [
    "samplers = []\n",
    "\n",
    "for i in range(4):\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, log_prob, args=[ivar])\n",
    "    print(\"ensemble %d: warm-up ...\" % (i+1))\n",
    "    state = sampler.run_mcmc(p0, nsteps // 4)\n",
    "    sampler.reset()\n",
    "    print(\"ensemble %d: sampling ...\" % (i+1))\n",
    "    sampler.run_mcmc(state, nsteps)\n",
    "    samplers.append(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we test within each ensemble, that each walker has a short auto-correlation time. Secondly, we check the Geweke drift from the first to last quarter of the chain. These checks are done for each parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for issues within chain 1 ...\n",
      "looking for issues within chain 2 ...\n",
      "looking for issues within chain 3 ...\n",
      "looking for issues within chain 4 ...\n"
     ]
    }
   ],
   "source": [
    "converged = True\n",
    "\n",
    "# require chain to be at least 5 auto-correlation lengths long\n",
    "min_autocorr_times = 5\n",
    "\n",
    "# Geweke convergence test threshold\n",
    "geweke_max = 1.0\n",
    "\n",
    "# whether you already want some plots showing the issue\n",
    "plot = False\n",
    "\n",
    "for c, sampler in enumerate(samplers):\n",
    "    print(\"looking for issues within chain %d ...\" % (c+1))\n",
    "    chain = sampler.get_chain()\n",
    "    flat_chain = sampler.get_chain(flat=True)\n",
    "    num_steps, num_walkers, ndim = chain.shape\n",
    "    # 0. analyse each variable\n",
    "    max_autocorrlength = 1\n",
    "    for i in range(ndim):\n",
    "        chain_variable = chain[:, :, i]\n",
    "        # 1. treat each walker as a independent chain\n",
    "        try:\n",
    "            for w in range(num_walkers):\n",
    "                chain_walker = chain_variable[:, w]\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    tau = emcee.autocorr.integrated_time(chain_walker, c=5, tol=50, quiet=False)\n",
    "                    tau = max(tau, 1)\n",
    "                max_autocorrlength = max(max_autocorrlength, tau)\n",
    "                if len(chain_walker) / tau < min_autocorr_times:\n",
    "                    print(\"autocorrelation is long for parameter %d: tau=%.1f -> %dx lengths\" % (i+1, tau, num_steps / tau))\n",
    "                    converged = False\n",
    "                    # you could plot chain_walker to visualise\n",
    "                    break\n",
    "        except emcee.autocorr.AutocorrError:\n",
    "            max_autocorrlength = np.inf\n",
    "            if min_autocorr_times > 0:\n",
    "                print(\"autocorrelation is too long for parameter %d to be estimated\" % (i+1))\n",
    "                converged = False\n",
    "                # you could plot chain_walker to visualise\n",
    "                break\n",
    "\n",
    "        if not converged:\n",
    "            break\n",
    "\n",
    "        # secondly, detect drift with geweke\n",
    "        a = flat_chain[:len(flat_chain) // 4, i]\n",
    "        b = flat_chain[-len(flat_chain) // 4:, i]\n",
    "        geweke_z = (a.mean() - b.mean()) / (np.var(a) + np.var(b))**0.5\n",
    "        if geweke_z > geweke_max:\n",
    "            print(\"geweke drift (z=%.1f) detected for parameter %d\" % (geweke_z, i+1))\n",
    "            converged = False\n",
    "            # you can plot histograms of a and b to visualise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is just a first smoke-test, if these tests do not succeed, you really are in trouble!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains = np.asarray([sampler.get_chain(flat=True) for sampler in samplers])\n",
    "\n",
    "rhat = arviz.rhat(arviz.convert_to_dataset(chains)).x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhat: 1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Rhat: %.2f\" % rhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the result\n",
    "\n",
    "You can find out more about the [Rhat](https://arviz-devs.github.io/arviz/api/generated/arviz.rhat.html) rank test. As a rule of thumb:\n",
    "\n",
    "If Rhat is below 1.01, then no convergence problem was detected.\n",
    "\n",
    "If Rhat is higher, you need to run your ensembles longer.\n",
    "\n",
    "And yes, I have seen very badly incorrect posteriors with Rhat=1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all posteriors\n",
    "\n",
    "Now we can put all the ensembles together to get very nice posterior sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = np.concatenate([sampler.get_chain(flat=True) for sampler in samplers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280000, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating this\n",
    "\n",
    "The [autoemcee package](https://johannesbuchner.github.io/autoemcee/) implements a wrapper for emcee (Affine-invariante Ensemble Sampling) and zeus (Ensemble Slice Sampling).\n",
    "\n",
    "It keeps increasing the number of MCMC steps until no convergence issues are found. The ensembles are run and initialised separately to be conservative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
